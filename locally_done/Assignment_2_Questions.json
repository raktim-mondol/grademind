{
    "title": "COMP9414 25T3 - Assignment 2 - Neural",
    "subtitle": "Networks, Tree-based and Ensemble Methods",
    "header_info": [
        "Open in Colab Open in Colab",
        "COMP9414 25T3 - Assignment 2 - Neural",
        "Networks, Tree-based and Ensemble Methods",
        "UNSW Sydney",
        "Designed by Maryam Hashemi, Zahra Donyavi, and Gustavo Batista.",
        "Last change: 14th October, 2025.",
        "Please add your S tudent name - zID here:",
        "Instructions",
        "Submission deadline:  Week 9, Friday, November 14, 5.00pm",
        "Submission Instructions"
    ],
    "tasks": [
        {
            "id": "0",
            "title": "Datasets description, downloading and loading",
            "marks": null,
            "description": "the data into a Pandas dataframe We will be using three datasets: 1. Adult Income dataset.  This is a binary classification dataset in which we want to predict if a person earns more than $50k/year. It is a mid-size dataset (48K examples) with 14 features of mixed data types (categorical and continuous) with missing values. 2. Cover Type dataset.  This is a large multi-class dataset with 580K examples and 54 features of mixed types. The objective is to predict the type of forest cover based on features such as soil type, elevation, and slope. In [ ]: 3. Credit Car d dataset . This is a binary classification dataset for detecting fraudulent transactions in credit card data. It is highly imbalanced, meaning that most transactions are normal, with some rare fraud cases. It has 284K instances and 30 numerical features. This table summarises the datasets. Dataset Problem T ype Featur e Type Size Adult Income dataset Binary Classification Categorical and Numerical 48,000 Cover Type dataset Multi-class Classification Categorical and Numerical 580,000 Credit Car d dataset Binary Classification Numerical 284,000 Let's start by downloading the data. The cell below will download and save the data into a local data  folder. W e will use the data later to train and assess our models. # Do not change the code in this cell. # This cell has no code to write. It downloads and unzips the datasets to your local disk. def download_and_extract (url, extract_to ): \"\"\" Download a zip file from the URL and extract it to the specified directory. Parameters: - url (str): The URL of the zip file to download. - extract_to (str): The directory where the zip file's contents will be extracted. Returns: None \"\"\" # Get the file, dataset names from the URL zip_filename  = url.split(\"/\")[-1] dataset_name  = zip_filename .split(\".\")[0] # Each dataset will have its folder extract_to  = extract_to  + \"/\" + dataset_name # Download the zip file print(f\"Downloading {zip_filename } from {url}...\") response  = requests .get(url) with open(zip_filename , \"wb\") as file: file.write(response .content) # Create the extraction directory if it doesn't exist if not os.path.exists(extract_to ): os.makedirs (extract_to ) # Unzip the file with zipfile.ZipFile(zip_filename , 'r') as zip_ref: zip_ref.extractall (extract_to ) # Remove the zip files os.remove(zip_filename ) # These are the URLs to the datasets. We have hosted the data on GitHub. urls = [ In [ ]: \"https://raw.githubusercontent.com/UNSW-COMP9414/Assignment2/main/data/adult/adult.zip\" \"https://raw.githubusercontent.com/UNSW-COMP9414/Assignment2/main/data/covertype/covert \"https://raw.githubusercontent.com/UNSW-COMP9414/Assignment2/main/data/creditcard/credi ] for i, url in enumerate (urls): download_and_extract (url, \"data\") Loading data into pandas The datasets are well-diversified in size (number of examples and features), number of class labels, feature types (continuous and discrete), class distribution, and presence of missing data. All datasets have pre-defined training and testing splits. W e will use the training set to train the models. Y ou may further split the training set into training and validation sets. The test set should only be used to assess and compare the models. The next cell has a supporting function that loads a specified dataset training and test sets into a pandas' dataframe. # Do not change the code in this cell. # This cell has no code to write. It is a helper function that loads data from this into a def load_train_test_data (path): \"\"\" Loads the train and test CSV files and returns them split into features (X) and labels Parameters: - path (str): Path to the train and test CSV files. Returns: - X_train (DataFrame): Features of the training dataset. - y_train (DataFrame): Labels of the training dataset. - X_test (DataFrame): Features of the test dataset. - y_test (DataFrame): Labels of the test dataset. \"\"\" # Load the training and testing data train_df  = pd.read_csv (f\"{path}/train.csv\" ) test_df = pd.read_csv (f\"{path}/test.csv\" ) # Select class label columns (those starting with 'Target') y_train = train_df .filter(regex='^Target' ) y_test = test_df.filter(regex='^Target' ) # Select feature columns (all columns except the ones with 'Target' prefix) X_train = train_df .drop(columns=y_train.columns) X_test = test_df.drop(columns=y_test.columns) return X_train, y_train, X_test, y_test # Example usage: path = \"data/adult\" print(f\"Loading {path}...\") X_train, y_train, X_test, y_test = load_train_test_data (path) In [ ]: print(f\"Train Features Shape: {X_train.shape}, Train Labels Shape: {y_train.shape}\") print(f\"Test Features Shape: {X_test.shape}, Test Labels Shape: {y_test.shape}\")",
            "subtasks": []
        },
        {
            "id": "1",
            "title": "Data preprocessing",
            "marks": "2 Marks",
            "description": "Your first task is to preprocess the datasets. Preprocessing usually involves data cleaning and transformation to improve data quality and prepare the data for the specific requirements of the learning approaches. For data preparation, we have the following tasks: 1. Missing imputation (all models) : The Adult Income dataset has missing values, and none of our learning algorithm implementations can directly handle missing data. T wo missing data treatments are eliminating the rows with missing data or replacing the missing values with estimated ones. Mean imput ation , as the name suggests, replaces missing values with the attribute mean, median (continuous features) or mode (discrete features). These statistics must only be estimated in the training set. 2. Featur e encoding (all models) : Neural networks, tree and random forest implementations available in the Scikit-Learn library do not handle categorical attributes directly. Therefore, these attributes need to be converted into numerical attributes. Although several encoding approaches exist, we will use one-hot encoding, as it is simple and recommended for categorical features with a small cardinality. 3. Class attr ibute encoding (neural netw orks only) : Neural networks also need a one-hot encoding for the class attribute. This step is not necessary for the tree models. 4. Rescaling attr ibute values (neural netw orks only) : The neural network's training benefits from rescaling the attribute values. In this task, we will convert each attribute to a number in the 0 to 1 range by using a simple linear rescaling: , where  is the recalled  value, is the minimum and  the maximum values for feature  in the training data.",
            "subtasks": [
                {
                    "id": "1.1",
                    "title": "Missing data removal or imputation",
                    "marks": "1 Mark",
                    "description": "Create a function missing_data(X_train, X_test)  that imputes missing values in the dataframes X_train  and X_test . When the function returns, both dataframes should have no missing values. # This cell will be assessed. Replace the ... with your code def missing_data (X_train, X_test): \"\"\" Impute missing values in the train and test DataFrames using median/mode imputation. Missing data statistics are only estimated on the training set and applied to the train Pro-tip: you can use Scikit-Learn's SimpleImputer. Parameters: - X_train (DataFrame): Training features. - X_test (DataFrame): Test features. Returns: - X_train_filled (DataFrame): Training features with no missing values.xs=x\u2212minf maxf\u2212minfxs x minf maxf f In [ ]: - X_test_filled (DataFrame): Test features with no missing values. \"\"\" ...  # TODO"
                },
                {
                    "id": "1.2",
                    "title": "Feature and class encoding",
                    "marks": "0.5 Marks",
                    "description": "Let's implement a function encoding(X_train, X_test)  that creates one-hot encodings for all categorical attributes. All categorical attributes are encoded as one-hot numeric features when the function returns. # This cell will be assessed. Replace the ... with your code def encoding (X_train, X_test): \"\"\" Encodes categorical features and class labels into one-hot numeric features. Ensure that you have a consistent encoding across training and test sets. Pro-tip: use Panda's get_dummies. Parameters: - X_train (DataFrame): Training features. - X_test (DataFrame): Test features. Returns: - X_train_encoded (DataFrame): One-hot encoded training features. - X_test_encoded (DataFrame): One-hot encoded test features. \"\"\" ...  # TODO"
                },
                {
                    "id": "1.3",
                    "title": "Rescaling attributes",
                    "marks": "0.5 Marks",
                    "description": "To conclude the pre-processing task, let's create a function rescale(X_train, X_test)  that rescales all continuous attributes so that each attribute is between 0 and 1. When the function returns, all numerical attributes should be rescaled. # This cell will be assessed. Replace the ... with your code def rescale(X_train, X_test): \"\"\" Rescales all continuous attributes in the train and test datasets to be in the range [0 Rescaling statistics should only be estimated on the training set and applied to the tr Pro-tip: use MinMaxScaler. Parameters: - X_train (DataFrame): Training features. - X_test (DataFrame): Test features. Returns: - X_train_rescaled (DataFrame): Rescaled training features. - X_test_rescaled (DataFrame): Rescaled test features. \"\"\" ... # TODO Preprocessing the datasets In [ ]: In [ ]: In the cell below, we will call your functions to preprocess the datasets. W e will create two versions of each dataset: the first is suitable for the tree models and will have no missing values and encoded attributes. The second will have no missing values, encoded categorical and class features, and numeric features rescaled. W e will save these datasets for use later. The datasets pre-processed for trees will be saved in a tree  folder. The datasets for neural networks will be saved in a nn folder. # Do not change the code in this cell. # This cell has no code to write. It calls your pre-processing functions and saves the prep for dataset in [\"adult\", \"covertype\" , \"creditcard\" ]: print(f\"Processing dataset: {dataset}\") # Load the train and test data X_train, y_train, X_test, y_test = load_train_test_data (\"data/\" + dataset) # Preprocessing for tree-based models tree_path  = f\"data/{dataset}/tree\" if not os.path.exists(tree_path ): os.makedirs (tree_path ) # Handle missing data X_train, X_test = missing_data (X_train, X_test) # Apply encoding features X_train_encoded , X_test_encoded  = encoding (X_train, X_test) # Concatenate X and y for train and test data. # For decision trees, we do not encode the class attribute train_tree  = pd.concat([X_train_encoded , y_train.reset_index (drop=True)], axis=1) test_tree  = pd.concat([X_test_encoded , y_test.reset_index (drop=True)], axis=1) # Save tree-preprocessed datasets train_tree .to_csv(f\"{tree_path }/train.csv\" , index=False) test_tree .to_csv(f\"{tree_path }/test.csv\" , index=False) # Preprocessing for neural networks nn_path = f\"data/{dataset}/nn\" if not os.path.exists(nn_path): os.makedirs (nn_path) # Apply encoding class attribute. For a regression dataset, the next line should do not y_train_encoded , y_test_encoded  = encoding (y_train, y_test) # Rescale the features X_train_rescaled , X_test_rescaled  = rescale(X_train_encoded , X_test_encoded ) # Concatenate X and y for train and test data train_nn  = pd.concat([X_train_rescaled , y_train_encoded .reset_index (drop=True)], axis=1 test_nn = pd.concat([X_test_rescaled , y_test_encoded .reset_index (drop=True)], axis=1) # Save nn-preprocessed datasets train_nn .to_csv(f\"{nn_path}/train.csv\" , index=False) test_nn.to_csv(f\"{nn_path}/test.csv\" , index=False)"
                }
            ]
        },
        {
            "id": "2",
            "title": "Model Training",
            "marks": "3 Marks",
            "description": "In [ ]: We have the data ready, and in this task, we will train some models for each dataset. Please add random.seed(42) when it is needed to make the results reproducible. The neural network will have three layers: the input layer ( ), one hidden layer ( ) and one output layer ( ). We will use a simple rule-of-thumb for the number of units in the hidden layer: .",
            "subtasks": [
                {
                    "id": "2.1",
                    "title": "Shallow neural net for classification",
                    "marks": "1 Mark",
                    "description": "Create a function train_shallow_net_class(X_train, y_train)  that trains a shallow neural net for classification using the training data X_train  and labels y_train . Use the following hyperparameters: 1. A single hidden layer with  units. 2. ReLU activation in the hidden layer and softmax on the output layer. 3. Categorical cross-entropy as loss function. 4. Train for 30 epochs. 5. Batch size of 32 instances. 6. Validation split of 20% of the training data. 7. Adam optimiser. After training, plot the lear ning cur ve showing both the training and validation accuracy over epochs. # This cell will be assessed. Replace the ... with your code def train_shallow_net_class (X_train, y_train): \"\"\" Trains a shallow neural net for classification problems with one hidden layer using the Parameters: - X_train (DataFrame): Training features. - y_train (DataFrame): Training labels (one-hot encoded for classification). - Dh (int): Number of units in the hidden layer. Returns: - model: Trained Keras neural network model. \"\"\" ... # TODO The next cell will call your function to train a shallow model for each classification dataset, compute the training time, and test error. # Do not change the code in this cell. # This cell has no code to write. It trains and assesses your shallow model using the class results = defaultdict (dict) for dataset in [\"adult\", \"covertype\" , \"creditcard\" ]: print(f\"Processing dataset: {dataset}\")i h o Dh=\u221aDi\u2217Do Dh=round(\u221aDi\u2217Do) In [ ]: In [ ]: # Load the train and test data X_train, y_train, X_test, y_test = load_train_test_data (f\"data/{dataset}/nn/\") start = time.time() model = train_shallow_net_class (X_train, y_train) end = time.time() test_loss , test_accuracy  = model.evaluate (X_test, y_test) print(f'Test error rate: {1 - test_accuracy :.4f}') print(f'Runtime to train the model: {end-start} seconds' ) results[\"Neural Net\" ].setdefault (dataset, {}) results[\"Neural Net\" ][dataset][\"Prediction quality\" ] =  test_accuracy          # Error r results[\"Neural Net\" ][dataset][\"Training time\" ] = end-start"
                },
                {
                    "id": "2.2",
                    "title": "Tree-based and Ensemble Models for",
                    "marks": "2 Mark",
                    "description": "Classification Implement the following functions that train different models using the training data X_train  and labels y_train . Each function should return a trained Scikit-Learn classifier. train_classification_tree(X_train, y_train)  \u2014 trains a Decision T ree model for classification. train_bagging(X_train, y_train)  \u2014 trains a Bagging model for classification. train_random_forest(X_train, y_train)  \u2014 trains a Random Forest model for classification. train_adaboost(X_train, y_train)  \u2014 trains an AdaBoost model for classifcation. # This cell will be assessed. Replace the ... with your code def train_classification_tree (X_train, y_train): \"\"\" Trains a Decision Tree for classification. Parameters: - X_train (DataFrame): Training features. - y_train (DataFrame): Training class labels. Returns: - model: Trained Decision Tree Classifier. \"\"\" ...  # TODO: Create and fit a DecisionTreeClassifier(random_state=42) return model def train_bagging (X_train, y_train): \"\"\" Trains a Bagging ensemble using Decision Trees as base learners. Parameters: - X_train (DataFrame): Training features. In [ ]: - y_train (DataFrame): Training class labels. Returns: - model: Trained Bagging Classifier. \"\"\" ...  # TODO: Create and fit a BaggingClassifier with DecisionTreeClassifier as base_est return model def train_random_forest (X_train, y_train): \"\"\" Trains a Random Forest for classification. Parameters: - X_train (DataFrame): Training features. - y_train (DataFrame): Training class labels. Returns: - model: Trained Random Forest Classifier. \"\"\" ...  # TODO: Create and fit a RandomForestClassifier(random_state=42) return model def train_adaboost (X_train, y_train): \"\"\" Trains an AdaBoost ensemble with Decision Stumps as weak learners. Parameters: - X_train (DataFrame): Training features. - y_train (DataFrame): Training class labels. Returns: - model: Trained AdaBoost Classifier. \"\"\" ...  # TODO: Create and fit an AdaBoostClassifier using DecisionTreeClassifier() return model The code below executes the tree models and records the test accuracy and training time. # Do not change the code in this cell. # This cell has no code to write. It trains and assesses your decision tree model using the from sklearn.model_selection  import StratifiedKFold , learning_curve import numpy as np import matplotlib.pyplot  as plt for dataset in [\"adult\", \"covertype\" , \"creditcard\" ]: print(f\"Processing dataset: {dataset}\") # Load the train and test data X_train, y_train, X_test, y_test = load_train_test_data (f\"data/{dataset}/tree/\") # Flatten y arrays y_train = np.ravel(y_train) y_test = np.ravel(y_test) In [ ]: # ---------------------------- # Decision Tree # ---------------------------- print(\"Training Decision Tree model\" ) start = time.time() model = train_classification_tree (X_train, y_train) end = time.time() y_pred = model.predict(X_test) test_accuracy  = accuracy_score (y_test, y_pred) print(f'Test error rate (Decision Tree): {1 - test_accuracy :.4f}') print(f'Runtime: {end-start:.2f} seconds' ) results[\"Decision Tree\" ].setdefault (dataset, {}) results[\"Decision Tree\" ][dataset][\"Prediction quality\" ] = test_accuracy results[\"Decision Tree\" ][dataset][\"Training time\" ] = end - start # ---------------------------- # Bagging # ---------------------------- print(\"Training Bagging model\" ) start = time.time() model = train_bagging (X_train, y_train) end = time.time() y_pred = model.predict(X_test) test_accuracy  = accuracy_score (y_test, y_pred) print(f'Test error rate (Bagging): {1 - test_accuracy :.4f}') print(f'Runtime: {end-start:.2f} seconds' ) results[\"Bagging\" ].setdefault (dataset, {}) results[\"Bagging\" ][dataset][\"Prediction quality\" ] = test_accuracy results[\"Bagging\" ][dataset][\"Training time\" ] = end - start # ---------------------------- # Random Forest # ---------------------------- print(\"Training Random Forest model\" ) start = time.time() model = train_random_forest (X_train, y_train) end = time.time() y_pred = model.predict(X_test) test_accuracy  = accuracy_score (y_test, y_pred) print(f'Test error rate (Random Forest): {1-test_accuracy :.4f}') print(f'Runtime: {end-start:.2f} seconds' ) results[\"Random Forest\" ].setdefault (dataset, {}) results[\"Random Forest\" ][dataset][\"Prediction quality\" ] = test_accuracy results[\"Random Forest\" ][dataset][\"Training time\" ] = end - start # ---------------------------- # AdaBoost # ---------------------------- print(\"Training AdaBoost model\" ) start = time.time() model = train_adaboost (X_train, y_train) end = time.time() y_pred = model.predict(X_test) test_accuracy  = accuracy_score (y_test, y_pred) print(f'Test error rate (AdaBoost): {1-test_accuracy :.4f}') print(f'Runtime: {end-start:.2f} seconds' ) results[\"AdaBoost\" ].setdefault (dataset, {}) results[\"AdaBoost\" ][dataset][\"Prediction quality\" ] = test_accuracy results[\"AdaBoost\" ][dataset][\"Training time\" ] = end - start Summarising the Results The next cell will summarise the results obtained in a single table. # Do not change the code in this cell. # This cell has no code to write. It summarises the results in a tabular format def format_values (row): \"\"\"Format numeric values to 4 decimal places.\"\"\" return {k: f\"{v:.4f}\" if isinstance (v, float) else v for k, v in row.items()} def print_results_table (results): \"\"\" Converts a nested dictionary of results into a table and prints it with separation line \"\"\" # Flatten the nested dictionary into a list of rows flattened_data  = [ {\"Dataset\" : dataset, \"Model\": model, **metrics} for model, datasets  in results.items() for dataset, metrics in datasets .items() ] # Sort the data by the \"Dataset\" column flattened_data_sorted  = sorted(flattened_data , key=lambda x: x[\"Dataset\" ]) # Add separator rows between datasets formatted_data  = [] previous_dataset  = None for row in flattened_data_sorted : if previous_dataset  and row[\"Dataset\" ] != previous_dataset : # Insert a separator row formatted_data .append({key: \"----\" for key in row.keys()}) formatted_data .append(format_values (row)) previous_dataset  = row[\"Dataset\" ] # Extract headers headers = list(formatted_data [0].keys()) # Generate and print the table table = tabulate (formatted_data , headers=\"keys\", tablefmt =\"pretty\" , missingval =\"N/A\") print(table) print_results_table (results)"
                }
            ]
        },
        {
            "id": "3",
            "title": "Report (20 Marks)",
            "marks": null,
            "description": "In [ ]: Based on the provided code and your knowledge of ensemble learning and neural networks, answer the following questions. Y our responses should be written directly under each question cell in the notebook. Please include all necessary components, such as your code, results, plots, and explanations.",
            "subtasks": [
                {
                    "id": "3.1",
                    "title": "Preprocessing",
                    "marks": "2 Marks",
                    "description": "As we mentioned earlier, we used rescaling for our shallow neural network but not for the other decision tree models. Can you explain why rescaling is not necessary for tree-based models? Why is rescaling necessary for neural network models? What would happen if we do not rescale in neural networks? # Add you answer here ...."
                },
                {
                    "id": "3.2",
                    "title": "Model Fine Tuning",
                    "marks": "4 Marks",
                    "description": "Investigate how model complexity affects the performance of the algorithms studied in this assignment using the Cover Type dataset . For Decision T rees, Random Forests, Bagging T rees, and AdaBoost, vary hyperparameters such as max_depth, the number of trees (n_estimators), optimizer, etc. T o examine how model complexity influences algorithm performance, record the training, validation, and test losses and accuracies, and present your results in plots. For each model, create a separate plot showing how accuracy and loss changes on the test set  as you vary the hyperparameters. (2 marks) Answer the following questions in your report: 1. How do the training and test accuracies change as model complexity increases? (1 mark) 2. Do you observe any signs of overfitting  in each of your models? Explain why you believe overfitting occurs, or why you think your models do not exhibit overfitting. (1 mark) # Add you answer here ...."
                },
                {
                    "id": "3.3",
                    "title": "Imbalanced Data",
                    "marks": "7 Marks",
                    "description": "For this part, compare the behaviour of Decision T ree, Bagging , Random For est, and AdaBoost models under the following scenario. Develop a code that receives a dataset as input and determines whether it is imbalanced  or not. (1 mark) Test your code on three given datasets, and identify whether there is any highly imbalanced dataset among the three given ones? (1 mark) If there is an imbalanced dataset, use that dataset and report the performance of each of the trained models from T ask 2 using a confusion matrix, accuracy, precision, recall, and F1-score in a table. (2 marks) In [ ]: In [ ]: Develop a code that applies class w eighting  or resampling , test whether it improves performance, and report your results in a plot comparing the previous model performance with the new model performance, and mention whether you used class weighting or resampling. (2 marks) Discuss which model(s) handles class imbalance better and explain why. (1 mark) # Add you answer here ...."
                },
                {
                    "id": "3.4",
                    "title": "Noisy Labels",
                    "marks": "4 Marks",
                    "description": "For this part, compare the behaviour of Decision T ree, Bagging , Random For est, and AdaBoost models under the following scenario. Develop a code that receives a dataset as input and randomly flips n% o f the training labels . Use your code to randomly flip 20% o f the training labels  in the adult income dataset . (1 mark) Retrain each of the previous models from T ask 2 using the new noisy adult income dataset, and compare their performance ( confusion matr ix, accuracy , precision , recall , and F1-scor e) between the models on the original data and those trained on the noisy data using plots. (2 marks) Identify which model(s) is more robust to noise and explain the reason for its higher resistance. (1 mark) # Add you answer here ...."
                },
                {
                    "id": "3.5",
                    "title": "NN fine tuning",
                    "marks": "3 Marks",
                    "description": "Take the shallow neural network from T ask 2, keep the number of layers as one and modify the number of neurons. Plot the training and test accuracies and losses to record changes while you change number of neurons, and determine which setting is better based on accuracy . (1 mark) Do you observe any signs of overfitting in your plots? Explain your reasoning. (1 mark) What is the optimal number of neurons in your network based on your experimental results and plots? Is this number consistent with the rule of thumb? Explain your answer. (1 mark) # Add you answer here .... In [ ]: In [ ]: In [ ]:"
                }
            ]
        }
    ]
}