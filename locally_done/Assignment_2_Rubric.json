{
    "title": "COMP9414 Assignment 2 - Rubric",
    "subtitle": "Neural Networks, Tree-based and Ensemble Methods",
    "total_marks": 25,
    "tasks": [
        {
            "task_id": "1",
            "title": "Task 1: Data Preprocessing",
            "sub_tasks": [
                {
                    "sub_task_id": "1.1",
                    "description": "Missing data removal or imputation",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "1.2",
                    "description": "Feature and class encoding",
                    "marks": 0.5
                },
                {
                    "sub_task_id": "1.3",
                    "description": "Rescaling attributes",
                    "marks": 0.5
                }
            ]
        },
        {
            "task_id": "2",
            "title": "Task 2: Model Training",
            "sub_tasks": [
                {
                    "sub_task_id": "2.1",
                    "description": "Shallow neural net for classification",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "2.2",
                    "description": "Tree-based and Ensemble Models for Classification",
                    "marks": 2.0
                }
            ]
        },
        {
            "task_id": "3",
            "title": "Task 3: Report",
            "sub_tasks": [
                {
                    "sub_task_id": "3.1",
                    "description": "Preprocessing Analysis:\n- Explain why rescaling is not necessary for tree-based models.\n- Explain why rescaling is necessary for neural networks.\n- Explain what happens if we do not rescale in neural networks.",
                    "marks": 2.0
                },
                {
                    "sub_task_id": "3.2.1",
                    "description": "Model Fine Tuning - Plots:\nCreate separate plots for each model (DT, RF, Bagging, AdaBoost) showing accuracy and loss changes on the test set as hyperparameters vary.",
                    "marks": 2.0
                },
                {
                    "sub_task_id": "3.2.2",
                    "description": "Model Fine Tuning - Analysis:\nExplain how training and test accuracies change as model complexity increases.",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "3.2.3",
                    "description": "Model Fine Tuning - Overfitting:\nDiscuss observations regarding overfitting and explain reasoning.",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "3.3.1",
                    "description": "Imbalanced Data - Detection Code:\nDevelop code to determine if a dataset is imbalanced.",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "3.3.2",
                    "description": "Imbalanced Data - Identification:\nTest code on 3 datasets and identify the imbalanced one.",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "3.3.3",
                    "description": "Imbalanced Data - Performance Table:\nReport performance (confusion matrix, accuracy, precision, recall, F1) of models on the imbalanced dataset.",
                    "marks": 2.0
                },
                {
                    "sub_task_id": "3.3.4",
                    "description": "Imbalanced Data - Handling:\nApply class weighting or resampling, test improvement, and report results in a plot comparing performance.",
                    "marks": 2.0
                },
                {
                    "sub_task_id": "3.3.5",
                    "description": "Imbalanced Data - Discussion:\nDiscuss which model handles class imbalance better and explain why.",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "3.4.1",
                    "description": "Noisy Labels - Code:\nDevelop code to randomly flip n% (20%) of training labels in adult income dataset.",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "3.4.2",
                    "description": "Noisy Labels - Retraining & Comparison:\nRetrain models on noisy data. Compare performance (metrics + plots) vs original models.",
                    "marks": 2.0
                },
                {
                    "sub_task_id": "3.4.3",
                    "description": "Noisy Labels - Robustness:\nIdentify which model(s) is more robust to noise and explain why.",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "3.5.1",
                    "description": "NN Fine Tuning - Experiments:\nPlot training/test accuracies/losses while modifying number of neurons. Determine best setting based on accuracy.",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "3.5.2",
                    "description": "NN Fine Tuning - Overfitting:\nObserve and explain overfitting signs in the plots.",
                    "marks": 1.0
                },
                {
                    "sub_task_id": "3.5.3",
                    "description": "NN Fine Tuning - Optimal Neurons:\nDetermine optimal number of neurons and discuss consistency with rule of thumb.",
                    "marks": 1.0
                }
            ]
        }
    ]
}